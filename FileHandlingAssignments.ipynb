{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - A sample script of Game of Thrones was taken from the page and stored in the file conv.txt in the dataset folder. Your task is to read the file and do the following:\n",
    "1. Find out the number of unique characters in the sample conversation?\n",
    "2. Create a new text file for each of the characters with their name and store the unique\n",
    "words said by them in their respective file. Store one word in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique characters in the sample conversation is 17\n"
     ]
    }
   ],
   "source": [
    "# Question 1: Find out the number of unique characters in the sample conversation ?\n",
    "\n",
    "# Let's open conv.txt file\n",
    "fileContents = ''\n",
    "with open('dataset/conv.txt', 'r') as f:\n",
    "    fileContents = f.readlines()\n",
    "\n",
    "# we would split the line of contents and would take first part of it (excluding \\n, of course)\n",
    "# Now, we know that set always contains the unique elements, hence would convert the list onto set\n",
    "\n",
    "unique_character_list = []\n",
    "for line in fileContents:\n",
    "    if line.split(':')[0] != '\\n':\n",
    "        unique_character_list.append(line.split(':')[0])\n",
    "    \n",
    "unique_character_set = set(unique_character_list)\n",
    "print('The number of unique characters in the sample conversation is {}'.format(len(unique_character_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Create a new text file for each of the characters with their name and \n",
    "# store the unique words said by them in their respective file. Store one word in one line.\n",
    "\n",
    "# Creating dictionary to have key as character and value as words spoken, as list\n",
    "# later we would convert the value of dictionary to a set, from the list\n",
    "dict_words = {}\n",
    "for u_c in unique_character_set:\n",
    "    dict_words[u_c] = []\n",
    "\n",
    "for line in fileContents:\n",
    "    # handling new lines etc.\n",
    "    if len(line) >= 2:\n",
    "        character = line.split(':')[0]\n",
    "        words = line.split(':')[1].split(' ')\n",
    "        dict_words[character].extend(words)\n",
    "\n",
    "# storing only the unique words\n",
    "for k in dict_words.keys():\n",
    "    dict_words[k] = list(set(dict_words[k]))\n",
    "    \n",
    "    # removing exclamation marks & lowering the texts\n",
    "    # there were special characters like â€™ in the file, hence used encoding/decoding\n",
    "    # ref used: https://www.kite.com/python/answers/how-to-remove-non-ascii-characters-in-python\n",
    "    dict_words[k] = [x.replace('\\n', '').replace('.', '').replace('?', '').replace('!', '').lower().encode(\"ascii\", \"ignore\").decode() for x in dict_words[k]]\n",
    "    \n",
    "    # removing blank string\n",
    "    dict_words[k].remove('')\n",
    "    \n",
    "    # write in the files with character as file name and contents as words spoken (per line)\n",
    "    with open(k + \".txt\", \"w\") as fw:\n",
    "        for l in dict_words[k]:\n",
    "            fw.write(l + \"\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
